{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T15:04:01.101400Z",
     "start_time": "2025-04-04T15:03:59.299740Z"
    }
   },
   "source": [
    "# Import Libraries for my AI Agent\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.groq import Groq\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from agno.tools.yfinance import YFinanceTools"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:04:01.119368Z",
     "start_time": "2025-04-04T15:04:01.104107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variables\n",
    "# GROQ\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "#AGNOS\n",
    "AGNOS_API_KEY = os.getenv(\"AGNOS_API_KEY\")"
   ],
   "id": "ad69bbeaad98e765",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "261e67ed39b2e10b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T15:05:18.550094Z",
     "start_time": "2025-04-04T15:04:01.377949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simplified News Agent\n",
    "news_agent = Agent(\n",
    "    name=\"News Analyst\",\n",
    "    role=\"Get top 3 market-moving news items\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    instructions=[\n",
    "        \"Format:\",\n",
    "        \"1. [Date] Headline (Source)\",\n",
    "        \"2. Sentiment: Positive/Neutral/Negative\",\n",
    "        \"3. Key point (1 sentence)\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Corrected Financial Agent\n",
    "financial_agent = Agent(\n",
    "    name=\"Financial Analyst\",\n",
    "    role=\"Get key financial metrics\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    tools=[YFinanceTools(\n",
    "        stock_price=True,\n",
    "        stock_fundamentals=True,  # This includes P/E ratio\n",
    "        key_financial_ratios=True\n",
    "    )],\n",
    "    instructions=[\n",
    "        \"Show data in this table format:\",\n",
    "        \"| Metric       | Value |\",\n",
    "        \"|--------------|-------|\",\n",
    "        \"| Price        |       |\",\n",
    "        \"| P/E Ratio    |       |\",\n",
    "        \"| 52-Week High |       |\",\n",
    "        \"| 52-Week Low  |       |\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Simplified Recommendation Agent\n",
    "recommendation_agent = Agent(\n",
    "    name=\"Investment Advisor\",\n",
    "    role=\"Provide concise recommendations\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    instructions=[\n",
    "        \"Provide:\",\n",
    "        \"1. Short-term outlook (1 sentence)\",\n",
    "        \"2. Long-term outlook (1 sentence)\",\n",
    "        \"3. Key risk (1 bullet point)\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Coordinator Agent\n",
    "coordinator = Agent(\n",
    "    name=\"Research Coordinator\",\n",
    "    role=\"Combine key insights\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    team=[news_agent, financial_agent, recommendation_agent],\n",
    "    instructions=[\n",
    "        \"Create brief report with:\",\n",
    "        \"1. Top News (3 items max)\",\n",
    "        \"2. Financial Snapshot (table)\",\n",
    "        \"3. Recommendation Summary\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Execute with focused query\n",
    "coordinator.print_response(\n",
    "    \"Provide a concise analysis of NVIDIA's current market position\",\n",
    "    stream=True\n",
    ")"
   ],
   "id": "7699733794ab8a70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0379fd071bd24e4fbbfb1e1e8024e991"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIError",
     "evalue": "Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAPIError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 68\u001B[39m\n\u001B[32m     53\u001B[39m coordinator = Agent(\n\u001B[32m     54\u001B[39m     name=\u001B[33m\"\u001B[39m\u001B[33mResearch Coordinator\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     55\u001B[39m     role=\u001B[33m\"\u001B[39m\u001B[33mCombine key insights\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     64\u001B[39m     markdown=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     65\u001B[39m )\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# Execute with focused query\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m \u001B[43mcoordinator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprint_response\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mProvide a concise analysis of NVIDIA\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43ms current market position\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m     71\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\projects\\agentic-ai\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py:3823\u001B[39m, in \u001B[36mAgent.print_response\u001B[39m\u001B[34m(self, message, messages, audio, images, videos, files, stream, markdown, show_message, show_reasoning, show_full_reasoning, console, tags_to_include_in_markdown, **kwargs)\u001B[39m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m render:\n\u001B[32m   3821\u001B[39m     live_log.update(Group(*panels))\n\u001B[32m-> \u001B[39m\u001B[32m3823\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3824\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3825\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3826\u001B[39m \u001B[43m    \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m=\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3827\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3828\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvideos\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvideos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3829\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3830\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   3831\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3832\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3833\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mresp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mRunResponse\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   3834\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mRunEvent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_response\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\projects\\agentic-ai\\.venv\\Lib\\site-packages\\agno\\agent\\agent.py:586\u001B[39m, in \u001B[36mAgent._run\u001B[39m\u001B[34m(self, message, stream, audio, images, videos, files, messages, stream_intermediate_steps, **kwargs)\u001B[39m\n\u001B[32m    584\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stream:\n\u001B[32m    585\u001B[39m     model_response = ModelResponse()\n\u001B[32m--> \u001B[39m\u001B[32m586\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmodel_response_chunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresponse_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_messages\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    587\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# If the model response is an assistant_response, yield a RunResponse\u001B[39;49;00m\n\u001B[32m    588\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmodel_response_chunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mModelResponseEvent\u001B[49m\u001B[43m.\u001B[49m\u001B[43massistant_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    589\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# Process content and thinking\u001B[39;49;00m\n\u001B[32m    590\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmodel_response_chunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\projects\\agentic-ai\\.venv\\Lib\\site-packages\\agno\\models\\base.py:510\u001B[39m, in \u001B[36mModel.response_stream\u001B[39m\u001B[34m(self, messages)\u001B[39m\n\u001B[32m    508\u001B[39m \u001B[38;5;66;03m# Generate response\u001B[39;00m\n\u001B[32m    509\u001B[39m assistant_message.metrics.start_timer()\n\u001B[32m--> \u001B[39m\u001B[32m510\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.process_response_stream(\n\u001B[32m    511\u001B[39m     messages=messages, assistant_message=assistant_message, stream_data=stream_data\n\u001B[32m    512\u001B[39m )\n\u001B[32m    513\u001B[39m assistant_message.metrics.stop_timer()\n\u001B[32m    515\u001B[39m \u001B[38;5;66;03m# Populate assistant message from stream data\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\projects\\agentic-ai\\.venv\\Lib\\site-packages\\agno\\models\\base.py:482\u001B[39m, in \u001B[36mModel.process_response_stream\u001B[39m\u001B[34m(self, messages, assistant_message, stream_data)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprocess_response_stream\u001B[39m(\n\u001B[32m    477\u001B[39m     \u001B[38;5;28mself\u001B[39m, messages: List[Message], assistant_message: Message, stream_data: MessageData\n\u001B[32m    478\u001B[39m ) -> Iterator[ModelResponse]:\n\u001B[32m    479\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    480\u001B[39m \u001B[33;03m    Process a streaming response from the model.\u001B[39;00m\n\u001B[32m    481\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m482\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse_delta\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minvoke_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_response_delta\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparse_provider_response_delta\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse_delta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield from\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_populate_stream_data_and_assistant_message\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstream_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massistant_message\u001B[49m\u001B[43m=\u001B[49m\u001B[43massistant_message\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_response\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_response_delta\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\projects\\agentic-ai\\.venv\\Lib\\site-packages\\groq\\_streaming.py:46\u001B[39m, in \u001B[36mStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Iterator[_T]:\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iterator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\projects\\agentic-ai\\.venv\\Lib\\site-packages\\groq\\_streaming.py:91\u001B[39m, in \u001B[36mStream.__stream__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     88\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m message \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(message, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m     89\u001B[39m                 message = \u001B[33m\"\u001B[39m\u001B[33mAn error occurred during streaming\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m APIError(\n\u001B[32m     92\u001B[39m                 message=message,\n\u001B[32m     93\u001B[39m                 request=\u001B[38;5;28mself\u001B[39m.response.request,\n\u001B[32m     94\u001B[39m                 body=data[\u001B[33m\"\u001B[39m\u001B[33merror\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     95\u001B[39m             )\n\u001B[32m     97\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m process_data(data={\u001B[33m\"\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\"\u001B[39m: data, \u001B[33m\"\u001B[39m\u001B[33mevent\u001B[39m\u001B[33m\"\u001B[39m: sse.event}, cast_to=cast_to, response=response)\n\u001B[32m     99\u001B[39m \u001B[38;5;66;03m# Ensure the entire stream is consumed\u001B[39;00m\n",
      "\u001B[31mAPIError\u001B[39m: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the response to a html file\n",
    "with open(\"output.html\", \"w\") as f:\n",
    "    f.write(coordinator.response)"
   ],
   "id": "44e449b1f6d94fa1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
